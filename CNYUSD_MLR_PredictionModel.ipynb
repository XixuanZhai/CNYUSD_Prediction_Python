{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CNYUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>6.8159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>6.7720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>6.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>6.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>6.5486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  CNYUSD\n",
       "0 2010-01-01  6.8159\n",
       "1 2010-04-01  6.7720\n",
       "2 2010-07-01  6.6784\n",
       "3 2010-10-01  6.6124\n",
       "4 2011-01-01  6.5486"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch CNYUSD exchange rate data\n",
    "cnyusd_data = yf.download('CNY=X', start='2010-01-01', end='2024-03-31', interval='3mo')\n",
    "\n",
    "# Extract the adjusted close prices for the CNYUSD exchange rate\n",
    "cnyusd_prices = cnyusd_data['Adj Close'].reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "cnyusd_prices.columns = ['Date', 'CNYUSD']\n",
    "\n",
    "# Display the first few rows of the CNYUSD data\n",
    "cnyusd_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel profile\n",
    "file_path = 'G:\\\\My Drive\\\\semester 3\\\\Fin 612\\\\currency report\\\\Data612.xlsx'  #change this into data/612data.xlsx\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# read 'all data' worksheet\n",
    "data_sheet = pd.read_excel(xls, sheet_name='All data')\n",
    "\n",
    "# extract data from Q1 2010 to Q1 2024 \n",
    "china_data = data_sheet.iloc[1:8, 22:79].reset_index(drop=True)  # row 2 to 8 contain china's data 第3行到第9行为中国的数据\n",
    "usa_data = data_sheet.iloc[8:15, 22:79].reset_index(drop=True)   # rows 9 to 15 contain USA's data 第10行到第16行为美国的数据\n",
    "\n",
    "# rename columns to quarterly names from Q1 2010 to Q1 2024\n",
    "quarter_names = [f\"Q{i}\" for i in range(1, 58)]\n",
    "china_data.columns = quarter_names\n",
    "usa_data.columns = quarter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create China's and USA's variables as DataFrames\n",
    "china_indices = {\n",
    "    'CPI_CHN': china_data.iloc[4].values,\n",
    "    'PPI_CHN': china_data.iloc[5].values,\n",
    "    'UR_CHN': china_data.iloc[3].values,\n",
    "    'FR_CHN': china_data.iloc[2].values,\n",
    "    'IP_CHN': china_data.iloc[0].values,\n",
    "    'INT_CHN': china_data.iloc[1].values,\n",
    "    'CA_CHN': china_data.iloc[6].values\n",
    "}\n",
    "\n",
    "usa_indices = {\n",
    "    'CPI_USA': usa_data.iloc[4].values,\n",
    "    'PPI_USA': usa_data.iloc[5].values,\n",
    "    'UR_USA': usa_data.iloc[3].values,\n",
    "    'FR_USA': usa_data.iloc[2].values,\n",
    "    'IP_USA': usa_data.iloc[0].values,\n",
    "    'INT_USA': usa_data.iloc[1].values,\n",
    "    'CA_USA': usa_data.iloc[6].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the two column we need\n",
    "cnyusd_prices = pd.DataFrame({\n",
    "    'Date': cnyusd_prices['Date'],\n",
    "    'CNYUSD': cnyusd_prices['CNYUSD']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CA of China are most of the time positive(Trade surplus) but contains negative values, while the US CA are all negative(Trade deficit). Therefore when calculating the logarithmic difference, there should be invalid values. So we scaled the CA data of both country to (1e-6, 100000) to avoid error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 创建 MinMaxScaler 实例，将数据缩放到 [1e-6, 100000] 范围\n",
    "scaler = MinMaxScaler(feature_range=(1e-6, 100000))\n",
    "\n",
    "# 对中国和美国的 CA 数据进行标准化\n",
    "china_ca_scaled = scaler.fit_transform(china_data.iloc[6].values.reshape(-1, 1))\n",
    "usa_ca_scaled = scaler.fit_transform(usa_data.iloc[6].values.reshape(-1, 1))\n",
    "\n",
    "# 将标准化后的 CA 数据转换为数组\n",
    "china_ca_scaled = china_ca_scaled.flatten()\n",
    "usa_ca_scaled = usa_ca_scaled.flatten()\n",
    "\n",
    "# Create China's and USA's variables as DataFrames\n",
    "china_indices['CA_CHN']= china_ca_scaled\n",
    "usa_indices['CA_USA']= usa_ca_scaled\n",
    "\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'ln(CPI_ratio_CHN)': np.log(np.array(china_indices['CPI_CHN'][1:], dtype=float) / np.array(china_indices['CPI_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['CPI_USA'][1:], dtype=float) / np.array(usa_indices['CPI_USA'][:-1], dtype=float)),\n",
    "    'ln(PPI_ratio_CHN)': np.log(np.array(china_indices['PPI_CHN'][1:], dtype=float) / np.array(china_indices['PPI_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['PPI_USA'][1:], dtype=float) / np.array(usa_indices['PPI_USA'][:-1], dtype=float)),\n",
    "    'ln(UR_ratio_CHN)': np.log(np.array(china_indices['UR_CHN'][1:], dtype=float) / np.array(china_indices['UR_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['UR_USA'][1:], dtype=float) / np.array(usa_indices['UR_USA'][:-1], dtype=float)),\n",
    "    'ln(FR_ratio_CHN)': np.log(np.array(china_indices['FR_CHN'][1:], dtype=float) / np.array(china_indices['FR_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['FR_USA'][1:], dtype=float) / np.array(usa_indices['FR_USA'][:-1], dtype=float)),\n",
    "    'ln(INT_ratio_CHN)': np.log(np.array(china_indices['INT_CHN'][1:], dtype=float) / np.array(china_indices['INT_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['INT_USA'][1:], dtype=float) / np.array(usa_indices['INT_USA'][:-1], dtype=float)),\n",
    "    'ln(IP_ratio_CHN)': np.log(np.array(china_indices['IP_CHN'][1:], dtype=float) / np.array(china_indices['IP_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['IP_USA'][1:], dtype=float) / np.array(usa_indices['IP_USA'][:-1], dtype=float)),\n",
    "    'ln(CA_ratio_CHN)': np.log(np.array(china_indices['CA_CHN'][1:], dtype=float) / np.array(china_indices['CA_CHN'][:-1], dtype=float)) - np.log(np.array(usa_indices['CA_USA'][1:], dtype=float) / np.array(usa_indices['CA_USA'][:-1], dtype=float))\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建因变量 Y (人民币兑美元汇率变化)\n",
    "Y = np.log(cnyusd_prices['CNYUSD'].shift(-1)) - np.log(cnyusd_prices['CNYUSD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 去除缺失值\n",
    "X = X.dropna()\n",
    "Y = Y.dropna()\n",
    "\n",
    "# 拆分训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 加入截距项\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R2 scores: [-2.6267695  -0.58061166 -4.71178597 -1.62110659 -0.03846329]\n",
      "Mean cross-validation R2 score: -1.9157474019119554\n",
      "Test predictions: [ 0.00561419 -0.00212892 -0.00299105  0.00063839 -0.00660669  0.00061505\n",
      "  0.00033834  0.00824024  0.0227797   0.00845509  0.00260992  0.00062292]\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn的LinearRegression进行交叉验证\n",
    "model_cv = LinearRegression()\n",
    "\n",
    "# 因为X_train和Y_train包含了回归的自变量和因变量，因此我们可以直接进行交叉验证\n",
    "# 使用5折交叉验证\n",
    "cv_scores = cross_val_score(model_cv, X_train, Y_train, cv=5, scoring='r2')\n",
    "\n",
    "# 输出交叉验证得分\n",
    "print(\"Cross-validation R2 scores:\", cv_scores)\n",
    "print(\"Mean cross-validation R2 score:\", np.mean(cv_scores))\n",
    "\n",
    "# 拟合模型\n",
    "model_cv.fit(X_train, Y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "Y_pred_cv = model_cv.predict(X_test)\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"Test predictions:\", Y_pred_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0006479889030012718\n",
      "Mean Absolute Error (MAE): 0.022144025717379678\n",
      "      Actual  Predicted\n",
      "0  -0.006462   0.005614\n",
      "5  -0.011751  -0.002129\n",
      "33  0.035660  -0.002991\n",
      "13 -0.002893   0.000638\n",
      "19  0.000726  -0.006607\n",
      "50 -0.032325   0.000615\n",
      "36  0.022979   0.000338\n",
      "26  0.040424   0.008240\n",
      "44 -0.016557   0.022780\n",
      "12 -0.014613   0.008455\n",
      "54 -0.031417   0.002610\n",
      "3  -0.009695   0.000623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 计算均方误差 (MSE) 和平均绝对误差 (MAE)\n",
    "mse = mean_squared_error(Y_test, Y_pred_cv)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_cv)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# 输出预测结果与真实值的差异\n",
    "comparison = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred_cv})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Variable  Coefficient\n",
      "0              const     0.000000\n",
      "1  ln(CPI_ratio_CHN)    -0.873930\n",
      "2  ln(PPI_ratio_CHN)     0.022518\n",
      "3   ln(UR_ratio_CHN)    -0.035290\n",
      "4   ln(FR_ratio_CHN)     0.144990\n",
      "5  ln(INT_ratio_CHN)    -0.012624\n",
      "6   ln(IP_ratio_CHN)    -0.000761\n",
      "7   ln(CA_ratio_CHN)    -0.001445\n"
     ]
    }
   ],
   "source": [
    "# 查看模型的回归系数\n",
    "coefficients = pd.DataFrame({'Variable': X_train.columns, 'Coefficient': model_cv.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS regression using all data yielded an R-squared of 19.7%, indicating that the model explains approximately 19.7% of the variation in the dependent variable (CNYUSD). The Prob(F-statistic) of 0.136 exceeds 0.05, suggesting that the overall model is not statistically significant, meaning the explanatory variables do not significantly explain changes in the dependent variable. While none of the coefficients are statistically significant, the p-values for CPI_ratio_CHN, FR_ratio_CHN, INT_ratio_CHN, and CA_ratio_CHN are close to significance. The negative coefficient for CPI implies that an increase in China's CPI relative to the U.S. could lead to RMB depreciation. The positive coefficient for foreign reserves (FR) suggests that higher reserves might result in RMB appreciation, while the negative coefficient for CA indicates that an increase in the current account balance between China and the U.S. could contribute to RMB depreciation. The model's limitations may stem from fundamental differences in U.S. and Chinese economic structures and government policies, as factors influencing exchange rates are highly complex and dynamic. Simple linear regression may not fully capture these nuances, suggesting that additional factors or adjustments to the model structure are required to improve explanatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 CNYUSD   R-squared:                       0.197\n",
      "Model:                            OLS   Adj. R-squared:                  0.080\n",
      "Method:                 Least Squares   F-statistic:                     1.684\n",
      "Date:                Fri, 25 Oct 2024   Prob (F-statistic):              0.136\n",
      "Time:                        16:33:05   Log-Likelihood:                 136.38\n",
      "No. Observations:                  56   AIC:                            -256.8\n",
      "Df Residuals:                      48   BIC:                            -240.6\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                -0.0019      0.003     -0.584      0.562      -0.009       0.005\n",
      "ln(CPI_ratio_CHN)    -0.5845      0.320     -1.827      0.074      -1.228       0.059\n",
      "ln(PPI_ratio_CHN)     0.0349      0.220      0.159      0.875      -0.407       0.477\n",
      "ln(UR_ratio_CHN)     -0.0333      0.020     -1.673      0.101      -0.073       0.007\n",
      "ln(FR_ratio_CHN)      0.1727      0.092      1.871      0.067      -0.013       0.358\n",
      "ln(INT_ratio_CHN)    -0.0150      0.008     -1.771      0.083      -0.032       0.002\n",
      "ln(IP_ratio_CHN)      0.0035      0.033      0.108      0.915      -0.062       0.070\n",
      "ln(CA_ratio_CHN)     -0.0014      0.001     -1.952      0.057      -0.003    4.05e-05\n",
      "==============================================================================\n",
      "Omnibus:                        3.844   Durbin-Watson:                   1.673\n",
      "Prob(Omnibus):                  0.146   Jarque-Bera (JB):                3.418\n",
      "Skew:                           0.519   Prob(JB):                        0.181\n",
      "Kurtosis:                       2.379   Cond. No.                         664.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 假设你已经有自变量 X 和因变量 Y\n",
    "# 你可能需要给 X 数据集添加一个常数项（截距项）\n",
    "X_with_const = sm.add_constant(X)  # 添加截距项\n",
    "\n",
    "# 使用 statsmodels 进行 OLS 回归\n",
    "model = sm.OLS(Y, X_with_const)\n",
    "results = model.fit()\n",
    "\n",
    "# 查看回归结果，包括系数的显著性、p 值等\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
